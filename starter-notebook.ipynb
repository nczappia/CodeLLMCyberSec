{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "* https://huggingface.co/datasets/iamtarun/code_instructions_120k_alpaca/viewer\n",
    "* https://www.atyun.com/datasets/files/sahil2801/code_instructions_120k.html (no access as of right now)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Dataframe\n",
    "### Strengths\n",
    "* Data Analysis\n",
    "* Data Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "code_df = pd.read_parquet(\"train-00000-of-00001-d9b93805488c263e.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121959, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['instruction', 'input', 'output', 'prompt'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "instruction    Create a function to calculate the sum of a se...\n",
       "input                                            [1, 2, 3, 4, 5]\n",
       "output         # Python code\\ndef sum_sequence(sequence):\\n  ...\n",
       "prompt         Below is an instruction that describes a task....\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_df.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pyarrow Table\n",
    "### Strengths\n",
    "* Reading specific columns\n",
    "* Filtering\n",
    "* Working with raw data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "\n",
    "code_table = pq.read_table(\"train-00000-of-00001-d9b93805488c263e.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121959, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "instruction: string\n",
       "input: string\n",
       "output: string\n",
       "prompt: string\n",
       "-- schema metadata --\n",
       "huggingface: '{\"info\": {\"features\": {\"instruction\": {\"dtype\": \"string\", \"' + 165"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_table.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyarrow.Table\n",
       "instruction: string\n",
       "input: string\n",
       "output: string\n",
       "prompt: string\n",
       "----\n",
       "instruction: [[\"Create a MySQL query to find the most expensive product from the table \"products\".\"]]\n",
       "input: [[\"\"]]\n",
       "output: [[\"SELECT * FROM products ORDER BY price DESC LIMIT 1;\"]]\n",
       "prompt: [[\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
       "\n",
       "### Instruction:\n",
       "Create a MySQL query to find the most expensive product from the table \"products\".\n",
       "\n",
       "### Input:\n",
       "\n",
       "\n",
       "### Response:\n",
       "SELECT * FROM products ORDER BY price DESC LIMIT 1;\"]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_table.take([8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks\n",
    "* Get number of examples for each language\n",
    "* Get list of large Code LLMs (including the used ones)\n",
    "    * Analyze their performance\n",
    "* Find code that  can generate the malicious code (look through paper and details)\n",
    "* ***Extra*** -- How does gpt-3.5-turbo determine malicious code?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Examples for Each Language\n",
    "### Ideas\n",
    "* Get a model to identify what language a snippet is written in\n",
    "* Implement rules/checks that are specific to each language\n",
    "#### Dataset with General Code Examples\n",
    "* https://huggingface.co/datasets/bigcode/the-stack\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Large Code LLMs\n",
    "#### From The Paper\n",
    "* CodeLlama (7B)\n",
    "    * https://github.com/meta-llama/codellama\n",
    "* DeepSeek-Coder (6.7B)\n",
    "    * https://github.com/deepseek-ai/DeepSeek-Coder\n",
    "    * https://huggingface.co/deepseek-ai/deepseek-coder-6.7b-instruct\n",
    "* StarCoder2 (7B)\n",
    "    * https://github.com/bigcode-project/starcoder2\n",
    "#### Others\n",
    "* Codex\n",
    "    * https://github.com/openai/human-eval\n",
    "    * Restricted access\n",
    "    * Python\n",
    "* GitHub Copilot\n",
    "    * Not open source\n",
    "* CodeT5\n",
    "    * https://huggingface.co/Salesforce/codet5-base\n",
    "    * Snippets:\n",
    "        * // Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "pipe = pipeline(\"text2text-generation\", model=\"Salesforce/codet5-base\")\n",
    "        * // Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/codet5-base\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Salesforce/codet5-base\")\n",
    "\n",
    "* AlphaCode\n",
    "    * Not public\n",
    "    * Not open source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CodeLlama (*In model-repos directory*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DeepSeek-Coder (torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"deepseek-ai/deepseek-coder-6.7b-instruct\", trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"deepseek-ai/deepseek-coder-6.7b-instruct\", trust_remote_code=True, torch_dtype=torch.bfloat16).cuda()\n",
    "messages=[\n",
    "    { 'role': 'user', 'content': \"write a quick sort algorithm in python.\"}\n",
    "]\n",
    "inputs = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\").to(model.device)\n",
    "# tokenizer.eos_token_id is the id of <|EOT|> token\n",
    "outputs = model.generate(inputs, max_new_tokens=512, do_sample=False, top_k=50, top_p=0.95, num_return_sequences=1, eos_token_id=tokenizer.eos_token_id)\n",
    "print(tokenizer.decode(outputs[0][len(inputs[0]):], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### StarCoder2 (*In model-repos directory*)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CodeT5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
